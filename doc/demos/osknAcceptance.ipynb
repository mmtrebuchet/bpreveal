{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de2a7167-47e9-420a-9eea-a85facc844a3",
   "metadata": {},
   "source": [
    "This is the integration test for BPReveal. It trains up an OSKN model and runs a full suite of analysis on it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2243c981-d832-4408-b798-e654b6cec0bc",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cce2be-a2fa-48c3-b307-2f31ac531e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] = os.environ[\"PATH\"] + \":/n/apps/CentOS7/bin/\"\n",
    "import bpreveal\n",
    "print(bpreveal.__version__)\n",
    "import bpreveal.utils as utils\n",
    "from bpreveal.tools.slurm import configSlurm, jobsNonGpu, jobsGpu, jobsLocal, writeDependencyScript\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [10,8]\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "import numpy as np\n",
    "import pybedtools\n",
    "import pysam\n",
    "import pyBigWig\n",
    "import h5py\n",
    "import bpreveal.plotting as bprplots\n",
    "import bpreveal.motifUtils as motifUtils\n",
    "import bpreveal.colors as bprcolors\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07a5177-a99c-40aa-91c6-482950670287",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIRECTORY=\"/n/projects/cm2363/public-bpreveal/5.0.0/repo\"\n",
    "BPREVEAL_VERSION = \"5.0.0\"\n",
    "WORKING_DIRECTORY=BASE_DIRECTORY + \"/test/acceptance/oskn-5.0.0\"\n",
    "DATA_DIRECTORY=\"/n/projects/cm2363/bpreveal/demoData/oskn\"\n",
    "SCRIPTS_DIR=\"/n/projects/cm2363/manuscript-bpreveal/src\"\n",
    "SRC_DIR = BASE_DIRECTORY + \"/src\"\n",
    "CONDA_ENV_NAME=\"/n/projects/cm2363/public-bpreveal/5.0.0/env\"\n",
    "SLURM_CONFIG=configSlurm([\"/home/cm2363/.zshrc\"],\n",
    "                         CONDA_ENV_NAME, WORKING_DIRECTORY, maxJobs=64)\n",
    "GENOME_FASTA=\"/n/data1/genomes/indexes/mm10/mm10.fa\"\n",
    "TF_NAMES = [\"oct4\", \"sox2\", \"klf4\", \"nanog\"]\n",
    "TEST_CHROMS = [\"chr\" + str(x) for x in [1, 8, 9]]\n",
    "VAL_CHROMS = [\"chr\" + str(x) for x in [2,3,4]]\n",
    "TRAIN_CHROMS = [\"chr\" + str(x) for x in [5,6,7,10,11,12,13,14,15,16,17,18,19]]\n",
    "NUM_THREADS_MAJOR=70\n",
    "NUM_THREADS_MINOR=20\n",
    "\n",
    "COLLECT_BENCHMARKS = True\n",
    "COLLECT_COVERAGE = True\n",
    "\n",
    "BENCH_EXE = \"/n/data1/benchmarks/bin/bench\"\n",
    "\n",
    "NUM_EPOCHS = 200\n",
    "LOG_LEVEL=\"INFO\"\n",
    "windowStart = 180924752-1000\n",
    "windowEnd = 180925152+1000\n",
    "windowLen = windowEnd - windowStart\n",
    "windowChrom = \"chr1\"\n",
    "bgProbs = [(1-0.42) /2, 0.21, 0.21, (1-0.42) /2]\n",
    "patternsToScan = {}\n",
    "for tf in TF_NAMES:\n",
    "    for model in [\"solo\", \"residual\", \"combined\", \"transformation\"]:\n",
    "        for mode in [\"profile\", \"counts\"]:\n",
    "            patNames = [[x, tf[0] + mode[0] + str(x)] for x in range(5)]\n",
    "            patternsToScan[f\"{tf}_{model}_{mode}\"] = {\"pos\": patNames} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3eaa78-adcc-44bc-a269-e1deaee20581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructCommand(executable, coverage=COLLECT_COVERAGE, benchmark=COLLECT_BENCHMARKS,\n",
    "                    doubleEscape = False, shortProgName=None):\n",
    "    execStr = executable + \" \"\n",
    "    if shortProgName is None:\n",
    "        shortProgName = executable\n",
    "    if coverage:\n",
    "        execStr = f\"coverage run $(which {execStr}) \"\n",
    "    if benchmark:\n",
    "        args = f\"--category=bpreveal --program-name={shortProgName} --program-version={BPREVEAL_VERSION}\"\n",
    "        if doubleEscape:\n",
    "            args = args + f\" --output=benchmarks/bench_{shortProgName}_${{{{SLURM_ARRAY_JOB_ID}}}}_${{{{SLURM_ARRAY_TASK_ID}}}}.json \"\n",
    "        else:\n",
    "            args = args + f\" --output=benchmarks/bench_{shortProgName}_${{SLURM_ARRAY_JOB_ID}}_${{SLURM_ARRAY_TASK_ID}}.json \"\n",
    "        execStr = f\"{BENCH_EXE} {args} {execStr} \"\n",
    "    return execStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de505de4-25cf-4a66-8b5e-33ef30de6b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {WORKING_DIRECTORY}/input\n",
    "!mkdir -p {WORKING_DIRECTORY}/bed\n",
    "!mkdir -p {WORKING_DIRECTORY}/json\n",
    "!mkdir -p {WORKING_DIRECTORY}/logs\n",
    "!mkdir -p {WORKING_DIRECTORY}/models\n",
    "!mkdir -p {WORKING_DIRECTORY}/modisco\n",
    "!mkdir -p {WORKING_DIRECTORY}/pred\n",
    "!mkdir -p {WORKING_DIRECTORY}/shap\n",
    "!mkdir -p {WORKING_DIRECTORY}/slurm\n",
    "!mkdir -p {WORKING_DIRECTORY}/slurm/benchmarks\n",
    "!mkdir -p {WORKING_DIRECTORY}/scan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0167df43-b8de-4066-8220-a0b734f14f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(WORKING_DIRECTORY + \"/slurm/.coveragerc\", \"w\") as fp:\n",
    "    fp.write(\n",
    "        \"[run]\\n\"\n",
    "        \"branch = True\\n\"\n",
    "        \"concurrency = multiprocessing\\n\"\n",
    "        \"omit = /tmp/*\\n\"\n",
    "        \"disable_warnings =\\n\"\n",
    "        \"    module-not-measured\\n\"\n",
    "        \"    module-not-imported\\n\"\n",
    "        \"parallel = true\\n\"\n",
    "        f\"source = {SRC_DIR}\\n    bpreveal\\n\"\n",
    "        \"\\n[report]\\n\"\n",
    "        \"exclude_also =\\n    assert\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810982bf-bbd7-44e1-97da-20bc0200d4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start building a list of jobs to run with dependencies\n",
    "jobSpecs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abb93dd-a95c-4496-a290-4c48d5bad6c7",
   "metadata": {},
   "source": [
    "# Length calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42b1918-2682-4954-8a70-8bb461958754",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_LENGTH=1000\n",
    "CONV1_SIZE=7\n",
    "PROFILE_CONV_SIZE=7\n",
    "input_length_str = !lengthCalc --output-len {OUTPUT_LENGTH} \\\n",
    "                               --n-dil-layers 9 \\\n",
    "                               --conv1-kernel-size {CONV1_SIZE} \\\n",
    "                               --profile-kernel-size {PROFILE_CONV_SIZE}\n",
    "INPUT_LENGTH=int(input_length_str[0])\n",
    "print(INPUT_LENGTH)\n",
    "RECEPTIVE_FIELD=INPUT_LENGTH - OUTPUT_LENGTH + 1\n",
    "print(RECEPTIVE_FIELD)\n",
    "BUFFER = (INPUT_LENGTH - OUTPUT_LENGTH) // 2\n",
    "print(BUFFER)\n",
    "MAX_JITTER = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c54f92-66a6-49ff-bd5f-72948af81440",
   "metadata": {},
   "outputs": [],
   "source": [
    "slurmNameCheckLength = jobsNonGpu(SLURM_CONFIG,\n",
    "    [constructCommand(\"lengthCalc\") + \"--output-len \"\n",
    "     \"{0:d}  --n-dil-layers 9 --conv1-kernel-size 25 \"\n",
    "     \"--profile-kernel-size 25\".format(OUTPUT_LENGTH)], \n",
    "            \"checkLengthCalc\", 1, 1, \"0:01:00\")\n",
    "jobSpecs.append([slurmNameCheckLength, []])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f34d5e-5ed9-43b2-88b3-c64cf33999c5",
   "metadata": {},
   "source": [
    "# Prepare bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3b7fe4-bed6-43da-9111-5c98a36360f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigwigFileNames = [[DATA_DIRECTORY + \"/\" + tfName + \"/counts.\" + strand + \".bw\"  \n",
    "                   for strand in [\"pos\", \"neg\"]]\n",
    "                  for tfName in TF_NAMES]\n",
    "summitBedFnames = [DATA_DIRECTORY + \"/\" + tfName + \"/idr-optimal-set.summit.bed\" \n",
    "                   for tfName in TF_NAMES]\n",
    "summitBedFnames += [DATA_DIRECTORY + \"/peaks-bak/\" + tfName + \".bed\"\n",
    "                    for tfName in TF_NAMES]\n",
    "headSpec = [{\"bigwig-names\" : flist, \"max-quantile\" : 1, \"min-counts\" : 1} \n",
    "          for flist in bigwigFileNames]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db13bcb8-11a9-4005-8ce0-82d29177895c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prepareBedPeaksConfig = {\n",
    "    \"heads\" : headSpec, \n",
    "    \"splits\" : {\"test-chroms\"  : TEST_CHROMS, \n",
    "                \"val-chroms\"   : VAL_CHROMS,\n",
    "                \"train-chroms\" : TRAIN_CHROMS,\n",
    "                \"regions\" : summitBedFnames},\n",
    "    \"genome\" : GENOME_FASTA,\n",
    "    \"output-length\" : OUTPUT_LENGTH, \n",
    "    \"input-length\" : INPUT_LENGTH,\n",
    "    \"max-jitter\" : MAX_JITTER,\n",
    "    \"output-prefix\" : WORKING_DIRECTORY + \"/bed/peak\", \n",
    "    \"resize-mode\" : \"center\", \n",
    "    \"remove-overlaps\" : True,\n",
    "    \"overlap-max-distance\" : 100,\n",
    "    \"num-threads\" : NUM_THREADS_MAJOR,\n",
    "    \"verbosity\" : LOG_LEVEL}\n",
    "\n",
    "with open(WORKING_DIRECTORY + \"/json/prepareBedPeaks.json\", \"w\") as fp:\n",
    "    json.dump(prepareBedPeaksConfig, fp, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a945747-c70c-477c-8696-bf54e93e81cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "slurmNamePrepareBedPeaks = jobsNonGpu(SLURM_CONFIG, \n",
    "        [constructCommand(\"prepareBed\") + \" {0:s}/json/prepareBedPeaks.json\".format(WORKING_DIRECTORY)], \n",
    "        \"prepareBedPeaks\", NUM_THREADS_MAJOR, 50, \"1:00:00\")\n",
    "jobSpecs.append([slurmNamePrepareBedPeaks, []])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383d75ab-d88b-4cc8-9aba-55b8216a95d2",
   "metadata": {},
   "source": [
    "# Tile Genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040772d0-ed6c-44b6-a27e-25e04e9cfac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "backgroundBase =  \"--genome {0:s} --output-length {1:d} --input-length {2:d} \"\\\n",
    "                 \"--chrom-edge-boundary 100000 --spacing 10000 --output-bed {3:s} \"\\\n",
    "                 \"{4:s} {5:s}\"\n",
    "blacklistArgs = \"--blacklist {0:s} --blacklist {1:s}\".format(\n",
    "    WORKING_DIRECTORY + \"/bed/peak_all.bed\",\n",
    "    WORKING_DIRECTORY + \"/bed/peak_reject.bed\")\n",
    "\n",
    "chromArgs = ' '.join([\"--allow-chrom {0:s}\".format(c) for c in (TRAIN_CHROMS + TEST_CHROMS + VAL_CHROMS)])\n",
    "\n",
    "cmdGenBackground = constructCommand(\"tileGenome\") + backgroundBase.format(\n",
    "    GENOME_FASTA, OUTPUT_LENGTH, INPUT_LENGTH, WORKING_DIRECTORY + \"/bed/tiling_all.bed\",\n",
    "    blacklistArgs, chromArgs)\n",
    "\n",
    "slurmNameGenBackground = jobsNonGpu(SLURM_CONFIG, [cmdGenBackground], \"genBackground\", 1, 10, \"1:00:00\")\n",
    "jobSpecs.append([slurmNameGenBackground, [slurmNamePrepareBedPeaks]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fed3c5-b984-4e5b-bdba-27254e02c44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "biasBigwigFnames = [DATA_DIRECTORY + \"/patchcap/counts.\" + strand + \".bw\" \n",
    "                    for strand in [\"pos\", \"neg\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc2bde2-8090-43b3-b73d-534b6ec0109a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "biasHeadSpec = [{\"bigwig-names\" : flist, \"max-quantile\" : 0.6, \"min-quantile\" : 0.01} \n",
    "          for flist in bigwigFileNames]\n",
    "biasHeadSpec = biasHeadSpec + [{\"bigwig-names\" : biasBigwigFnames, \n",
    "                            \"max-quantile\" : 0.95, \n",
    "                            \"min-quantile\" : 0.1} ]\n",
    "prepareBedNonPeaksConfig = {\n",
    "    \"heads\" : biasHeadSpec, \n",
    "    \"splits\" : {\"test-chroms\"  : TEST_CHROMS, \n",
    "                \"val-chroms\"   : VAL_CHROMS,\n",
    "                \"train-chroms\" : TRAIN_CHROMS,\n",
    "                \"regions\" : [WORKING_DIRECTORY + \"/bed/tiling_all.bed\"]},\n",
    "    \"genome\" : GENOME_FASTA,\n",
    "    \"output-length\" : OUTPUT_LENGTH,\n",
    "    \"input-length\" : INPUT_LENGTH,\n",
    "    \"max-jitter\" : MAX_JITTER,\n",
    "    \"output-prefix\" : WORKING_DIRECTORY + \"/bed/nonpeak\", \n",
    "    \"remove-overlaps\" : False,\n",
    "    \"resize-mode\" : \"center\",\n",
    "    \"num-threads\" : NUM_THREADS_MAJOR,\n",
    "    \"verbosity\" : LOG_LEVEL}\n",
    "\n",
    "with open(WORKING_DIRECTORY + \"/json/prepareBedNonPeaks.json\", \"w\") as fp:\n",
    "    json.dump(prepareBedNonPeaksConfig, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cc332e-744b-4d18-8f9e-7e69f799212b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "slurmNamePrepareBedNonPeaks = jobsNonGpu(SLURM_CONFIG,\n",
    "    [constructCommand(\"prepareBed\") + \"{0:s}/json/prepareBedNonPeaks.json\".format(WORKING_DIRECTORY)], \n",
    "    \"prepareBedNonPeaks\", NUM_THREADS_MAJOR, 50, \"1:00:00\")\n",
    "jobSpecs.append([slurmNamePrepareBedNonPeaks, [slurmNameGenBackground]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7532b8ef-20a2-49ee-b623-f3a443c0a0d2",
   "metadata": {},
   "source": [
    "# Building the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982118a2-5a80-4306-bae5-d3e5870ab0fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "configFnames = []\n",
    "for split in [\"train\", \"val\"]:\n",
    "    for dataset in [\"peak\", \"nonpeak\"]:\n",
    "        heads = []\n",
    "        for tfId, tfName in enumerate(TF_NAMES):\n",
    "            if(dataset == 'peak'):\n",
    "                heads.append({\n",
    "                    \"revcomp-task-order\" : \"auto\",\n",
    "                    \"bigwig-files\" : bigwigFileNames[tfId]})\n",
    "            else:\n",
    "                heads.append({\n",
    "                    \"revcomp-task-order\" : \"auto\",\n",
    "                    \"bigwig-files\" : biasBigwigFnames})\n",
    "        config = {\"genome\" : GENOME_FASTA, \n",
    "                  \"input-length\" : INPUT_LENGTH,\n",
    "                  \"output-length\" : OUTPUT_LENGTH,\n",
    "                  \"max-jitter\" : MAX_JITTER,\n",
    "                  \"regions\" : WORKING_DIRECTORY + \"/bed/\" + dataset + \"_\" + split + \".bed\",\n",
    "                  \"output-h5\" : WORKING_DIRECTORY + \"/input/\" + dataset + \"_\" + split + \".h5\",\n",
    "                  \"reverse-complement\" : True,\n",
    "                  \"heads\" : heads,\n",
    "                  \"verbosity\" : LOG_LEVEL}\n",
    "        configFname =WORKING_DIRECTORY + \"/json/prepareInput\" + dataset + \"_\" + split+ \".json\" \n",
    "        with open(configFname, \"w\") as fp:\n",
    "            json.dump(config, fp, indent=2)\n",
    "        configFnames.append(configFname)\n",
    "slurmNamePrepareTrainingData = jobsNonGpu(SLURM_CONFIG,\n",
    "    [constructCommand(\"prepareTrainingData\") + \"{0:s}\".format(configFname) \n",
    "                for configFname in configFnames], \n",
    "    \"prepareTrainingData\", 2, 20, \"1:00:00\")\n",
    "jobSpecs.append([slurmNamePrepareTrainingData, [slurmNamePrepareBedNonPeaks]])\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeb4b1c-9575-4f63-990f-3803b99d887c",
   "metadata": {},
   "source": [
    "# Training the bias model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aef2dba-7a89-4b4b-9dde-ba5fc9e8baa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "heads = []\n",
    "for tfName in TF_NAMES:\n",
    "    heads.append({\"num-tasks\" : 2, \n",
    "                  \"profile-loss-weight\" : 1, \n",
    "                  \"head-name\" : \"patchcap_\" + tfName,\n",
    "                  \"counts-loss-weight\" : 10,\n",
    "                  \"counts-loss-frac-target\" : 0.1})\n",
    "\n",
    "biasTrainConfig = {\n",
    "    \"settings\" : {\n",
    "        \"output-prefix\" : WORKING_DIRECTORY + \"/models/solo\", \n",
    "        \"epochs\" : NUM_EPOCHS,\n",
    "        \"max-jitter\" : 100,\n",
    "        \"early-stopping-patience\" : 20,\n",
    "        \"batch-size\" : 128,\n",
    "        \"learning-rate\" : 0.004,\n",
    "        \"learning-rate-plateau-patience\" : 5,\n",
    "        \"architecture\" : {\n",
    "            \"architecture-name\" : \"bpnet\", \n",
    "            \"input-length\" : INPUT_LENGTH,\n",
    "            \"output-length\" : OUTPUT_LENGTH,\n",
    "            \"model-name\" : \"patchcap\",\n",
    "            \"model-args\" : \"\",\n",
    "            \"filters\" : 16,\n",
    "            \"layers\" : 9,\n",
    "            \"input-filter-width\" : CONV1_SIZE,\n",
    "            \"output-filter-width\" : PROFILE_CONV_SIZE\n",
    "        }\n",
    "    },\n",
    "    \"train-data\" : WORKING_DIRECTORY + \"/input/nonpeak_train.h5\",\n",
    "    \"val-data\" : WORKING_DIRECTORY + \"/input/nonpeak_val.h5\",\n",
    "    \"heads\" : heads,\n",
    "    \"verbosity\" : LOG_LEVEL\n",
    "}\n",
    "\n",
    "\n",
    "with open(WORKING_DIRECTORY + \"/json/trainBias.json\", \"w\") as fp:\n",
    "    json.dump(biasTrainConfig, fp, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ccd4ae-da60-4fb9-8680-bd1458737a3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "slurmNameTrainSoloModel = jobsGpu(SLURM_CONFIG, \n",
    "    [constructCommand(\"trainSoloModel\") + \"{0:s}\".format(WORKING_DIRECTORY + \"/json/trainBias.json\")],\n",
    "    \"trainSolo\", 10, 30, \"10:00:00\")\n",
    "jobSpecs.append([slurmNameTrainSoloModel, [slurmNamePrepareTrainingData]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a5ddbb-67fa-4496-b29d-ea65282963a9",
   "metadata": {},
   "source": [
    "# makePredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641452f3-4b34-4bb4-bfb0-81afe24387b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "biasPredictConfig = {\n",
    "    \"settings\" : {\n",
    "        \"output-h5\" : WORKING_DIRECTORY + \"/pred/patchcap.h5\", \n",
    "        \"batch-size\" : 128,\n",
    "        \"heads\" : len(TF_NAMES),\n",
    "        \n",
    "        \"architecture\" : {\n",
    "            \"model-file\" : WORKING_DIRECTORY + \"/models/solo.keras\",\n",
    "            \"input-length\" : INPUT_LENGTH,\n",
    "            \"output-length\" : OUTPUT_LENGTH\n",
    "        }\n",
    "    },\n",
    "    \"genome\" : GENOME_FASTA, \n",
    "    \"bed-file\" : WORKING_DIRECTORY + \"/bed/peak_all.bed\",\n",
    "    \"num-threads\" : 4,\n",
    "    \"verbosity\" : LOG_LEVEL\n",
    "}\n",
    "\n",
    "\n",
    "with open(WORKING_DIRECTORY + \"/json/predictBias.json\", \"w\") as fp:\n",
    "    json.dump(biasPredictConfig, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdee6a45-41fd-49f7-bb82-8e88a6ca26e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "slurmNamePredictSolo = jobsNonGpu(SLURM_CONFIG,\n",
    "    [constructCommand(\"makePredictions\") + \"{0:s}\".format(WORKING_DIRECTORY + \"/json/predictBias.json\")],\n",
    "    \"predictSolo\", 10, 50, \"10:00:00\")\n",
    "jobSpecs.append([slurmNamePredictSolo, [slurmNameTrainSoloModel]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d305bf78-fdc3-4c8b-ac1e-0e8d80e95b69",
   "metadata": {},
   "source": [
    "# PredictToBigwig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f634da20-4246-41e5-8f73-a15c2248cb63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "bwCmdBase = \"--h5 {wd:s}/pred/patchcap.h5 \" +\\\n",
    "            \"--bw {wd:s}/pred/{outf:s}.bw \"+\\\n",
    "            \"--head-id {hid:d} --task-id {tid:d} --mode profile \"+\\\n",
    "            \"--threads {nt:d}\"\n",
    "bwCmds = []\n",
    "for headid, tfname in enumerate(TF_NAMES):\n",
    "    for tid, strand in enumerate([\"positive\", \"negative\"]):\n",
    "        cmd = constructCommand(\"predictToBigwig\") +  bwCmdBase.format(wd=WORKING_DIRECTORY, \n",
    "                               outf=tfname + \"_solo_\" + strand,\n",
    "                               hid=headid, tid=tid,\n",
    "                               nt=NUM_THREADS_MINOR)\n",
    "        bwCmds.append(cmd)\n",
    "\n",
    "slurmNamePredToBigwigSolo = jobsNonGpu(SLURM_CONFIG, bwCmds, \n",
    "           \"predToBigwigSolo\", NUM_THREADS_MINOR, 20, \"1:00:00\")\n",
    "\n",
    "jobSpecs.append([slurmNamePredToBigwigSolo, [slurmNamePredictSolo]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7537c2-bc8a-4def-a267-b0778b01d523",
   "metadata": {},
   "source": [
    "# makeLossPlots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47572a0-d875-487d-ad95-c8f7a50e913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmdLossPlots = constructCommand(\"makeLossPlots\") + \" --json {0:s}/models/solo.history.json --output {0:s}/models/solo.png\".format(WORKING_DIRECTORY)\n",
    "slurmNameLossPlotsSolo = jobsNonGpu(SLURM_CONFIG, [cmdLossPlots], \"lossPlots\", 1, 20, \"1:00:00\")\n",
    "jobSpecs.append([slurmNameLossPlotsSolo, [slurmNameTrainSoloModel]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5219df4-c6b6-425e-8df7-37123bc0159e",
   "metadata": {},
   "source": [
    "# Training the transformation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cce598e-eaed-4baa-b181-f4aacab3bd2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "heads = []\n",
    "for tfName in TF_NAMES:\n",
    "    heads.append({\"num-tasks\" : 2, \n",
    "                  \"profile-loss-weight\" : 1, \n",
    "                  \"head-name\" : \"patchcap_\" + tfName,\n",
    "                  \"counts-loss-weight\" : 100,\n",
    "                  \"counts-loss-frac-target\" : 0.1})\n",
    "\n",
    "transformationTrainConfig = {\n",
    "    \"settings\" : {\n",
    "        \"output-prefix\" : WORKING_DIRECTORY + \"/models/transformation\", \n",
    "        \"epochs\" : NUM_EPOCHS,\n",
    "        \"early-stopping-patience\" : 4,\n",
    "        \"batch-size\" : 128,\n",
    "        \"learning-rate\" : 0.04,\n",
    "        \"learning-rate-plateau-patience\" : 2,\n",
    "        \"solo-model-file\" : WORKING_DIRECTORY + \"/models/solo.keras\",\n",
    "        \"input-length\" : INPUT_LENGTH, \n",
    "        \"output-length\" : OUTPUT_LENGTH,\n",
    "        \"max-jitter\" : 100,\n",
    "        \"profile-architecture\" : {\n",
    "            \"name\" : \"simple\", \n",
    "            \"types\" : [\"linear\", \"sigmoid\"]},\n",
    "        \"counts-architecture\" : {\n",
    "            \"name\" : \"simple\", \n",
    "            \"types\" : [\"linear\", \"sigmoid\"]}},\n",
    "        \n",
    "    \"train-data\" : WORKING_DIRECTORY+ \"/input/peak_train.h5\",\n",
    "    \"val-data\" : WORKING_DIRECTORY + \"/input/peak_val.h5\",\n",
    "    \"heads\" : heads,\n",
    "    \"verbosity\" : LOG_LEVEL\n",
    "}\n",
    "with open(WORKING_DIRECTORY + \"/json/trainTransformation.json\", \"w\") as fp:\n",
    "    json.dump(transformationTrainConfig, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0396084b-c755-4b1f-873e-b82066068d77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "slurmNameTrainTransformation = jobsGpu(SLURM_CONFIG, \n",
    "    [constructCommand(\"trainTransformationModel\") + \" {0:s}\".format(WORKING_DIRECTORY + \"/json/trainTransformation.json\")],\n",
    "        \"trainTransformation\", 10, 60, \"10:00:00\")\n",
    "jobSpecs.append([slurmNameTrainTransformation, [slurmNameTrainSoloModel]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07862308-9a70-492f-9347-0e3066a71d58",
   "metadata": {},
   "source": [
    "# Transformation prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55883d6-60af-46e5-af04-2269e432dc7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformPredictConfig = {\n",
    "    \"settings\" : {\n",
    "        \"output-h5\" : WORKING_DIRECTORY + \"/pred/transformation.h5\", \n",
    "        \"batch-size\" : 128,\n",
    "        \"heads\" : len(TF_NAMES),\n",
    "        \n",
    "        \"architecture\" : {\n",
    "            \"model-file\" : WORKING_DIRECTORY + \"/models/transformation.keras\",\n",
    "            \"input-length\" : INPUT_LENGTH,\n",
    "            \"output-length\" : OUTPUT_LENGTH\n",
    "        }\n",
    "    },\n",
    "    \"genome\" : GENOME_FASTA, \n",
    "    \"bed-file\" : WORKING_DIRECTORY + \"/bed/peak_all.bed\",\n",
    "    \"num-threads\" : 1,\n",
    "    \"verbosity\" : LOG_LEVEL\n",
    "}\n",
    "\n",
    "\n",
    "with open(WORKING_DIRECTORY + \"/json/predictTransformation.json\", \"w\") as fp:\n",
    "    json.dump(transformPredictConfig, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bf0a8a-1f74-4e41-91f4-c9db7120005d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "slurmNamePredictTransformation = jobsNonGpu(SLURM_CONFIG, \n",
    "    [constructCommand(\"makePredictions\") + \" {0:s}\".format(WORKING_DIRECTORY + \"/json/predictTransformation.json\")],\n",
    "        \"predictTransformation\", 2, 50, \"10:00:00\")\n",
    "jobSpecs.append([slurmNamePredictTransformation, [slurmNameTrainTransformation]])\n",
    "\n",
    "bwCmdBase = constructCommand(\"predictToBigwig\", doubleEscape=True) +\\\n",
    "          \"--h5 {wd:s}/pred/transformation.h5 \" +\\\n",
    "          \"--bw {wd:s}/pred/{outf:s}.bw \"+\\\n",
    "          \"--head-id {hid:d} --task-id {tid:d} --mode profile \"+\\\n",
    "          \"--threads {nt:d}\"\n",
    "\n",
    "bwCmds = []\n",
    "for headid, tfname in enumerate(TF_NAMES):\n",
    "    for tid, strand in enumerate([\"positive\", \"negative\"]):\n",
    "        cmd = bwCmdBase.format(wd=WORKING_DIRECTORY, \n",
    "                               outf=tfname + \"_transformation_\" + strand,\n",
    "                               hid=headid, tid=tid,\n",
    "                               nt=NUM_THREADS_MINOR)\n",
    "        bwCmds.append(cmd)\n",
    "\n",
    "slurmNamePredToBigwigTransformation = jobsNonGpu(SLURM_CONFIG, bwCmds, \n",
    "           \"predToBigwigTransformation\", NUM_THREADS_MINOR, 20, \"1:00:00\")\n",
    "\n",
    "jobSpecs.append([slurmNamePredToBigwigTransformation, [slurmNamePredictTransformation]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fb4e16-5ddb-4272-bd97-18e775902709",
   "metadata": {},
   "source": [
    "# Training the combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3a64f2-3757-4f4d-97fe-c2806a4c6629",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "heads = []\n",
    "for i, tfName in enumerate(TF_NAMES):\n",
    "    heads.append({\"num-tasks\" : 2, \n",
    "                  \"profile-loss-weight\" : 1, \n",
    "                  \"head-name\" : \"combined_\" + tfName,\n",
    "                  \"counts-loss-weight\" : 100,\n",
    "                  \"counts-loss-frac-target\" : 0.1,\n",
    "                  \"use-bias-counts\" : i == 0 # Just to test the system, there's no reason to do this in a real model.\n",
    "                 })\n",
    "\n",
    "combinedTrainConfig = {\n",
    "    \"settings\" : {\n",
    "        \"output-prefix\" : WORKING_DIRECTORY + \"/models/joint\", \n",
    "        \"epochs\" : NUM_EPOCHS,\n",
    "        \"early-stopping-patience\" : 13,\n",
    "        \"batch-size\" : 128,\n",
    "        \"learning-rate\" : 0.004,\n",
    "        \"learning-rate-plateau-patience\" : 5,\n",
    "        \"max-jitter\" : 100,\n",
    "        \"transformation-model\" : {\n",
    "            \"transformation-model-file\" : WORKING_DIRECTORY + \"/models/transformation.keras\"\n",
    "        },\n",
    "        \"architecture\" : {\n",
    "            \"architecture-name\" : \"bpnet\", \n",
    "            \"input-length\" : INPUT_LENGTH,\n",
    "            \"output-length\" : OUTPUT_LENGTH,\n",
    "            \"model-name\" : \"joint\",\n",
    "            \"model-args\" : \"\",\n",
    "            \"filters\" : 64,\n",
    "            \"layers\" : 9,\n",
    "            \"input-filter-width\" : 7,\n",
    "            \"output-filter-width\" : 7\n",
    "        }\n",
    "    },\n",
    "    \"train-data\" : WORKING_DIRECTORY + \"/input/peak_train.h5\",\n",
    "    \"val-data\" : WORKING_DIRECTORY + \"/input/peak_val.h5\",\n",
    "    \"heads\" : heads,\n",
    "    \"verbosity\" : \"DEBUG\" # I need some debug output to test showTrainingProgress.\n",
    "}\n",
    "\n",
    "\n",
    "with open(WORKING_DIRECTORY + \"/json/trainCombined.json\", \"w\") as fp:\n",
    "    json.dump(combinedTrainConfig, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f549186b-79e3-42a0-a3a5-905ef6d94665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "slurmNameTrainCombined = jobsGpu(SLURM_CONFIG,\n",
    "    [constructCommand(\"trainCombinedModel\") + \"{0:s}\".format(WORKING_DIRECTORY + \"/json/trainCombined.json\")],\n",
    "    \"trainCombined\", 10, 60, \"10:00:00\")\n",
    "jobSpecs.append([slurmNameTrainCombined, [slurmNameTrainTransformation]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb561827-9a37-4de3-9799-eb0bb41e4c8a",
   "metadata": {},
   "source": [
    "# Predict combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d985c4d4-8eff-4a87-8852-983375e29400",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedPredictConfig = {\n",
    "    \"settings\" : { \n",
    "        \"output-h5\" : WORKING_DIRECTORY + \"/pred/combined.h5\", \n",
    "        \"batch-size\" : 128,\n",
    "        \"heads\" : len(TF_NAMES),\n",
    "        \n",
    "        \"architecture\" : {\n",
    "            \"model-file\" : WORKING_DIRECTORY + \"/models/joint_combined.keras\",\n",
    "            \"input-length\" : INPUT_LENGTH,\n",
    "            \"output-length\" : OUTPUT_LENGTH\n",
    "        }\n",
    "    },\n",
    "    \"genome\" : GENOME_FASTA,\n",
    "    \"bed-file\" : WORKING_DIRECTORY + \"/bed/peak_all.bed\",\n",
    "    \"num-threads\" : 2,\n",
    "    \"verbosity\" : LOG_LEVEL\n",
    "}\n",
    "with open(WORKING_DIRECTORY + \"/json/predictCombined.json\", \"w\") as fp:\n",
    "    json.dump(combinedPredictConfig, fp)\n",
    "#For the residual model, I just need to change a few terms:\n",
    "residualPredictConfig = combinedPredictConfig\n",
    "residualPredictConfig[\"settings\"][\"output-h5\"] = WORKING_DIRECTORY + \"/pred/residual.h5\"\n",
    "residualPredictConfig[\"settings\"][\"architecture\"][\"model-file\"] = WORKING_DIRECTORY + \"/models/joint_residual.keras\"\n",
    "with open(WORKING_DIRECTORY + \"/json/predictResidual.json\", \"w\") as fp:\n",
    "    json.dump(residualPredictConfig, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cee25b-c851-4c47-b5d6-28ba288c94e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "slurmNamePredictCombined = jobsGpu(SLURM_CONFIG, \n",
    "    [constructCommand(\"makePredictions\") + \" {0:s}\".format(WORKING_DIRECTORY + \"/json/predictCombined.json\"),\n",
    "     constructCommand(\"makePredictions\")+ \" {0:s}\".format(WORKING_DIRECTORY + \"/json/predictResidual.json\")],\n",
    "    \"predictCombined\", 1, 50, \"10:00:00\")\n",
    "jobSpecs.append([slurmNamePredictCombined, [slurmNameTrainCombined]])\n",
    "\n",
    "bwCmdBase = \"--h5 {wd:s}/pred/{inf:s}.h5 \" +\\\n",
    "            \"--bw {wd:s}/pred/{outf:s}.bw \"+\\\n",
    "            \"--head-id {hid:d} --task-id {tid:d} --mode profile \"+\\\n",
    "            \"--threads {nt:d}\"\n",
    "bwCmds = []\n",
    "for modelType in [\"residual\", \"combined\"]:\n",
    "    for headid, tfname in enumerate(TF_NAMES):\n",
    "        for tid, strand in enumerate([\"positive\", \"negative\"]):\n",
    "            cmd =constructCommand(\"predictToBigwig\") + bwCmdBase.format(wd=WORKING_DIRECTORY, \n",
    "                                   inf=modelType,\n",
    "                                   outf=tfname + \"_\" + modelType + \"_\" + strand,\n",
    "                                   hid=headid, tid=tid,\n",
    "                                   nt=NUM_THREADS_MINOR)\n",
    "            bwCmds.append(cmd)\n",
    "\n",
    "slurmNamePredToBigwigCombined = jobsNonGpu(SLURM_CONFIG, bwCmds, \n",
    "           \"predToBigwigCombined\", NUM_THREADS_MINOR, 20, \"1:00:00\")\n",
    "\n",
    "jobSpecs.append([slurmNamePredToBigwigCombined, [slurmNamePredictCombined]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9d62f7-c3f4-4db2-ab1a-f850655b6100",
   "metadata": {},
   "source": [
    "# Deriving flat importance scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bbda55-ac81-4c70-954d-fb576af8e1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeInterpretJson(tfNum, model, modelName):\n",
    "    return {\n",
    "        \"genome\" : GENOME_FASTA,\n",
    "        \"bed-file\" : WORKING_DIRECTORY + \"/bed/peak_test.bed\",\n",
    "        \"model-file\" : f\"{WORKING_DIRECTORY}/models/{model}.keras\", \n",
    "        \"input-length\" : INPUT_LENGTH,\n",
    "        \"output-length\" : OUTPUT_LENGTH,\n",
    "        \"heads\" : len(TF_NAMES),\n",
    "        \"head-id\": tfNum,\n",
    "        \"profile-task-ids\" : [0,1],\n",
    "        \"profile-h5\" : f\"{WORKING_DIRECTORY}/shap/{TF_NAMES[tfNum]}_{modelName}_profile.h5\",\n",
    "        \"counts-h5\" : f\"{WORKING_DIRECTORY}/shap/{TF_NAMES[tfNum]}_{modelName}_counts.h5\",\n",
    "        \"num-shuffles\" : 20,\n",
    "        \"kmer-size\" : tfNum + 1, # Just to exercise the code path.\n",
    "        \"verbosity\" : LOG_LEVEL}\n",
    "cmds = []\n",
    "for tfNum in range(len(TF_NAMES)):\n",
    "    for model, modelName in [[\"joint_combined\", \"combined\"], [\"joint_residual\", \"residual\"], [\"transformation\", \"transformation\"], [\"solo\", \"solo\"]]:\n",
    "        fname = f\"{WORKING_DIRECTORY}/json/shap_{TF_NAMES[tfNum]}_{model}.json\"\n",
    "        cmds.append(constructCommand(\"interpretFlat\") + \"{0:s}\".format(fname))\n",
    "        with open(fname, \"w\") as fp:\n",
    "            json.dump(makeInterpretJson(tfNum, model, modelName), fp)\n",
    "slurmNameInterpretFlat = jobsGpu(SLURM_CONFIG, cmds,\n",
    "        \"interpretFlat\", 5, 50, \"10:00:00\")\n",
    "jobSpecs.append([slurmNameInterpretFlat, [slurmNameTrainCombined]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d161237-dbed-45b3-b412-1467b1492c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapBwCmdBase = \"--h5 {wd:s}/shap/{tf:s}_{model:s}_{readout:s}.h5 \" +\\\n",
    "                \"--bw {wd:s}/shap/{tf:s}_{model:s}_{readout:s}.bw \"\n",
    "shapBwCmds = []\n",
    "for tfname in TF_NAMES:\n",
    "    for modelName in [\"combined\", \"residual\", \"transformation\", \"solo\"]:\n",
    "        for readout in [\"profile\", \"counts\"]:\n",
    "            cmd = constructCommand(\"shapToBigwig\") + shapBwCmdBase.format(wd=WORKING_DIRECTORY, \n",
    "                                       tf=tfname,\n",
    "                                       readout=readout,\n",
    "                                       model=modelName)\n",
    "            shapBwCmds.append(cmd)\n",
    "\n",
    "slurmNameShapToBigwig = jobsNonGpu(SLURM_CONFIG, shapBwCmds, \n",
    "           \"shapToBigwig\", 2, 20, \"1:00:00\")\n",
    "jobSpecs.append([slurmNameShapToBigwig, [slurmNameInterpretFlat]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d418ce90-7831-45bd-807c-429a9c195681",
   "metadata": {},
   "source": [
    "# ShapToNumpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026eca42-71ee-40a2-a354-bf900ec5dee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shapToNumpyCmdBase = \"--h5 {wd:s}/shap/{tf:s}_{model:s}_{readout:s}.h5 \" +\\\n",
    "                     \"--seqs {wd:s}/shap/seqs_{tf:s}_{model:s}_{readout:s}.npz \"+\\\n",
    "                     \"--scores {wd:s}/shap/scores_{tf:s}_{model:s}_{readout:s}.npz \"\n",
    "shapToNumpyCmds = []\n",
    "for tfname in TF_NAMES:\n",
    "    for modelName in [\"combined\", \"residual\", \"transformation\", \"solo\"]:\n",
    "        for readout in [\"profile\", \"counts\"]:\n",
    "            cmd = constructCommand(\"shapToNumpy\") + shapToNumpyCmdBase.format(wd=WORKING_DIRECTORY, \n",
    "                                            tf=tfname,\n",
    "                                            readout=readout,\n",
    "                                            model=modelName)\n",
    "            shapToNumpyCmds.append(cmd)\n",
    "\n",
    "slurmNameShapToNumpy = jobsNonGpu(SLURM_CONFIG, shapToNumpyCmds, \n",
    "           \"shapToNumpy\", 2, 20, \"1:00:00\")\n",
    "jobSpecs.append([slurmNameShapToNumpy, [slurmNameInterpretFlat]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c083e1-78d7-4b07-af93-2ec84565d341",
   "metadata": {},
   "source": [
    "# Modisco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d00142-e055-4671-af84-2630d267b933",
   "metadata": {},
   "outputs": [],
   "source": [
    "modiscoCmdBase = \"mkdir -p {wd:s}/modisco/{tf:s}_{model:s}_{readout:s}\\n\" +\\\n",
    "          constructCommand(\"modisco\", coverage=False, doubleEscape = True) + \" motifs \" +\\\n",
    "              \"-s {wd:s}/shap/seqs_{tf:s}_{model:s}_{readout:s}.npz \" +\\\n",
    "              \"-a {wd:s}/shap/scores_{tf:s}_{model:s}_{readout:s}.npz \"+\\\n",
    "              \"-n 10000 \" +\\\n",
    "              \"-w 1000 \"+\\\n",
    "              \"-o {wd:s}/modisco/{tf:s}_{model:s}_{readout:s}/modisco.h5 \"\n",
    "modiscoCmds = []\n",
    "for tfname in TF_NAMES:\n",
    "    for modelName in [\"combined\", \"residual\", \"transformation\", \"solo\"]:\n",
    "        for readout in [\"profile\", \"counts\"]:\n",
    "            cmd = modiscoCmdBase.format(wd=WORKING_DIRECTORY, \n",
    "                                        tf=tfname,\n",
    "                                        readout=readout,\n",
    "                                        model=modelName)\n",
    "            modiscoCmds.append(cmd)\n",
    "slurmNameModisco = jobsNonGpu(SLURM_CONFIG, modiscoCmds, \n",
    "           \"modisco\", NUM_THREADS_MINOR, 40, \"10:00:00\")\n",
    "jobSpecs.append([slurmNameModisco, [slurmNameShapToNumpy]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db140a6-c174-4cc7-bc47-09dd86d56a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "reportCmdBase = constructCommand(\"modisco\", coverage=False, doubleEscape = True) + \" report \" +\\\n",
    "              \"-i {wd:s}/modisco/{tf:s}_{model:s}_{readout:s}/modisco.h5 \" +\\\n",
    "              \"-o {wd:s}/modisco/{tf:s}_{model:s}_{readout:s}/ \"+\\\n",
    "              \"-n 2 \" +\\\n",
    "              \"-m /n/data1/JASPAR/2022/JASPAR2022_CORE_vertebrates_non-redundant_pfms_meme.txt \" +\\\n",
    "              \"\\n\\n{sd:s}/annotateModiscoHtml --vertebrate\" +\\\n",
    "              \" {wd:s}/modisco/{tf:s}_{model:s}_{readout:s}/motifs.html \" + \\\n",
    "              \" > {wd:s}/modisco/{tf:s}_{model:s}_{readout:s}/motifs_names.html\"\n",
    "              \n",
    "reportCmds = []\n",
    "for tfname in TF_NAMES:\n",
    "    for modelName in [\"combined\", \"residual\", \"transformation\", \"solo\"]:\n",
    "        for readout in [\"profile\", \"counts\"]:\n",
    "            cmd = reportCmdBase.format(wd=WORKING_DIRECTORY, \n",
    "                                       sd=SCRIPTS_DIR,\n",
    "                                       tf=tfname,\n",
    "                                       readout=readout,\n",
    "                                       model=modelName)\n",
    "            reportCmds.append(cmd)\n",
    "\n",
    "slurmNameModiscoReport = jobsNonGpu(SLURM_CONFIG, reportCmds, \n",
    "           \"modiscoReport\", 5, 5, \"1:00:00\")\n",
    "jobSpecs.append([slurmNameModiscoReport, [slurmNameModisco]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6aa49a-20cb-41f6-99b6-50cb66eb1ac2",
   "metadata": {},
   "source": [
    "# Making a PISA plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904c89e8-d2c1-4767-a205-9ec149ec885c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df32448b-f74a-431a-a144-d1532871e9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def writeRegion(genome, outFp, regionStart):\n",
    "    genomeStart = regionStart - BUFFER\n",
    "    genomeEnd = genomeStart + INPUT_LENGTH\n",
    "    seq = genome.fetch(windowChrom, genomeStart, genomeEnd)\n",
    "    outFp.write(\">{0:d}\\n\".format(regionStart))\n",
    "    outFp.write(seq.upper())\n",
    "    outFp.write(\"\\n\")\n",
    "\n",
    "with open(WORKING_DIRECTORY + \"/shap/pisa_regions.fa\", \"w\") as fp:\n",
    "    with pysam.FastaFile(GENOME_FASTA) as genome:\n",
    "        for regionStart in range(windowStart, windowEnd):\n",
    "            writeRegion(genome, fp, regionStart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e4a096-e1cd-48aa-b465-e54160b106ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cmds = []\n",
    "for tfid in range(len(TF_NAMES)):\n",
    "    for strand in [0,1]:\n",
    "        for model, modelName in [['joint_residual', \"residual\"], ['joint_combined', \"combined\"], ['transformation', \"transformation\"], ['solo', \"solo\"]]:\n",
    "            task_name = TF_NAMES[tfid] + \"_\" + [\"positive\", \"negative\"][strand]\n",
    "            pisa_config = {\"model-file\" : f\"{WORKING_DIRECTORY}/models/{model}.keras\", \n",
    "                           \"fasta-file\" : WORKING_DIRECTORY + \"/shap/pisa_regions.fa\", \n",
    "                           \"num-shuffles\" : 20, \n",
    "                           \"head-id\" : tfid,\n",
    "                           \"task-id\" : strand,\n",
    "                           \"output-h5\" : f\"{WORKING_DIRECTORY}/shap/pisa_{modelName}_{task_name}.h5\",\n",
    "                           \"input-length\" : INPUT_LENGTH,\n",
    "                           \"output-length\" : OUTPUT_LENGTH,\n",
    "                           \"kmer-size\" : strand + 1, # Just to exercise both possibilities.\n",
    "                           \"num-threads\" : strand + 1,\n",
    "                           \"make-predictions\" : True,\n",
    "                           \"correct-receptive-field\": True,\n",
    "                           \"verbosity\" : LOG_LEVEL}\n",
    "            jsonFname = f\"{WORKING_DIRECTORY}/json/pisa_{modelName}_{task_name}.json\"\n",
    "            with open(jsonFname, \"w\") as fp:\n",
    "                json.dump(pisa_config, fp)\n",
    "            cmds.append(constructCommand(\"interpretPisa\") + \" {0:s}\".format(jsonFname))\n",
    "\n",
    "slurmNameInterpretPisa = jobsGpu(SLURM_CONFIG, cmds, \"interpretPisa\", 5, 20, \"10:00:00\")\n",
    "jobSpecs.append([slurmNameInterpretPisa, [slurmNameTrainCombined]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd64db3-ca83-4d66-8439-c709ad71a745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When the PISA data are available, we can make the pisa plot and graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb60343-bb84-44dd-a1b5-3f44dcfd46c7",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac30da9-de06-473c-862c-5caea7085f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "metricsCmdBase = constructCommand(\"metrics\", doubleEscape = True) + \" --reference {ddir:s}/{tf:s}/counts.{strand:s}.bw \" +\\\n",
    "         \"--pred {wd:s}/pred/{tf:s}_combined_{longstrand:s}.bw \" +\\\n",
    "         \"--regions {wd:s}/bed/peak_all.bed \" +\\\n",
    "         \"--threads {nt:d} --apply-abs --skip-zeroes\"\n",
    "cmds = []\n",
    "for tfName in TF_NAMES:\n",
    "    for lstr, sstr in ((\"positive\", \"pos\"), (\"negative\", \"neg\")):\n",
    "        metricsCmd = metricsCmdBase.format(wd = WORKING_DIRECTORY, ddir=DATA_DIRECTORY, \n",
    "                                           tf=tfName, strand = sstr, longstrand=lstr,\n",
    "                                           nt=NUM_THREADS_MINOR)\n",
    "        cmds.append(metricsCmd)\n",
    "slurmNameMetrics = jobsNonGpu(SLURM_CONFIG, cmds, \"metrics\", NUM_THREADS_MINOR, 20, \"1:00:00\")\n",
    "jobSpecs.append([slurmNameMetrics, [slurmNamePredToBigwigCombined]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f99c289-45b3-4285-bcd4-9e8b04ee1afa",
   "metadata": {},
   "source": [
    "# showModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b38d913-4324-47e4-954d-6c3e362c0976",
   "metadata": {},
   "outputs": [],
   "source": [
    "slurmNameShowModel = jobsNonGpu(SLURM_CONFIG,\n",
    "    [constructCommand(\"showModel\") + (\" --model {wd:s}/models/joint_combined.keras \"\n",
    "     \"--png {wd:s}/models/joint_combined.png\").format(wd=WORKING_DIRECTORY)], \n",
    "            \"checkShowModel\", 1, 10, \"0:05:00\")\n",
    "jobSpecs.append([slurmNameShowModel, [slurmNameTrainCombined]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5b9016-42e7-46ee-8d9a-99a477f7977a",
   "metadata": {},
   "source": [
    "# checkJson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28de1a41-90df-486a-a2bd-60d665cfeea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "slurmNameCheckJson = jobsNonGpu(SLURM_CONFIG,\n",
    "    [constructCommand(\"checkJson\") + \" {wd:s}/json/prepareBedNonPeaks.json\".format(wd=WORKING_DIRECTORY),\n",
    "     constructCommand(\"checkJson\") + \" -s prepareBed {wd:s}/json/prepareBedNonPeaks.json\".format(wd=WORKING_DIRECTORY)], \n",
    "            \"checkCheckJson\", 1, 1, \"0:05:00\")\n",
    "jobSpecs.append([slurmNameCheckJson, []])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31b538c-dd08-4793-afff-0eb6894ab901",
   "metadata": {},
   "source": [
    "# Easy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820ec5e5-a887-44b6-afd5-fc9f9d27c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(WORKING_DIRECTORY + \"/slurm/testEasy.py\", \"w\") as fp:\n",
    "    prog = (\"#!/usr/bin/env python3\\nfrom bpreveal import utils\\nimport random\\n\"\n",
    "            \"utils.setVerbosity('WARNING')\\n\"\n",
    "            \"import os\\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\\n\"\n",
    "            \"seq=''.join(random.choices('ACGT', k={isize:d}))\\n\"\n",
    "            \"utils.easyPredict(seq, '{wd:s}/models/joint_combined.keras')\\n\"\n",
    "            \"utils.easyInterpretFlat(seq, '{wd:s}/models/joint_residual.keras', \"\n",
    "            \"{nh:d}, 0, [0,1])\\n\").format(wd=WORKING_DIRECTORY, isize=INPUT_LENGTH,\n",
    "                                         nh = len(TF_NAMES))\n",
    "    fp.write(prog)\n",
    "slurmNameCheckEasy = jobsGpu(SLURM_CONFIG,\n",
    "    [\"coverage run {wd:s}/slurm/testEasy.py\".format(wd=WORKING_DIRECTORY)], \n",
    "            \"checkEasy\", 3, 20, \"0:15:00\")\n",
    "jobSpecs.append([slurmNameCheckEasy, [slurmNameTrainCombined]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f762d58-0885-4ac5-8a00-84661d619afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(WORKING_DIRECTORY + \"/slurm/testEasyCpu.py\", \"w\") as fp:\n",
    "    prog = (\"#!/usr/bin/env python3\\nfrom bpreveal import utils\\nimport random\\n\"\n",
    "            \"utils.setVerbosity('WARNING')\\n\"\n",
    "            \"import os\\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\\n\"\n",
    "            \"seq=''.join(random.choices('ACGT', k={isize:d}))\\n\"\n",
    "            \"utils.easyPredict(seq, '{wd:s}/models/joint_combined.keras')\\n\"\n",
    "           ).format(wd=WORKING_DIRECTORY, isize=INPUT_LENGTH)\n",
    "    fp.write(prog)\n",
    "slurmNameCheckEasyCpu = jobsNonGpu(SLURM_CONFIG,\n",
    "    [\"coverage run {wd:s}/slurm/testEasyCpu.py\".format(wd=WORKING_DIRECTORY)], \n",
    "            \"checkEasyCpu\", 3, 20, \"0:15:00\")\n",
    "jobSpecs.append([slurmNameCheckEasyCpu, [slurmNameTrainCombined]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa867a5-81ac-490b-990f-f0a9b6b93cfb",
   "metadata": {},
   "source": [
    "# Motif scanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84230cb4-a6cd-47e7-b77e-fa0f455fd031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbef737-93e4-48c9-8c3c-4f6a637a3a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cmdsScan = []\n",
    "cmdsPostproc = []\n",
    "SCAN_BASE = constructCommand(\"motifSeqletCutoffs\", doubleEscape = True) + \" {cutoffFname:s}\\n    \" +\\\n",
    "            constructCommand(\"motifScan\", doubleEscape=True) + \" {scanFname:s}\\n    \"\n",
    "POSTPROC_BASE = constructCommand(\"motifAddQuantiles\", doubleEscape=True) + \" --seqlet-tsv {seqletTmpTsv:s} --scan-tsv {scanTmpTsv:s} \" +\\\n",
    "                    \"--seqlet-out {seqletTsv:s} --scan-out {scanTsv:s}\\n    \" +\\\n",
    "                constructCommand(\"bestMotifsOnly\", doubleEscape=True) + \" --metric contrib_match --in-tsv {scanTsv:s} --out-bed {scanBed:s}\\n    \" + \\\n",
    "                \"coverage run $(which bestMotifsOnly) --metric contrib_match_quantile --in-tsv {scanTsv:s} \" +\\\n",
    "                    \"--out-bed {scanBedFilt:s} --filter 'contrib_match_quantile > 0.5 or (seq_match_quantile > 0.5 and contrib_magnitude_quantile > 0.5)' \\n    \"\n",
    "\n",
    "\n",
    "doneCombined = False\n",
    "for pat in patternsToScan.keys():\n",
    "    curPats = patternsToScan[pat]\n",
    "    patternSpec = []\n",
    "    for mcName in curPats.keys():\n",
    "        patternSpec.append({\n",
    "            \"metacluster-name\" : mcName + \"_patterns\", \n",
    "            \"pattern-names\" : [\"pattern_{0:d}\".format(x[0]) for x in curPats[mcName]],\n",
    "            \"short-names\" : [x[1] for x in curPats[mcName]]})\n",
    "    seqletTsv =  WORKING_DIRECTORY + \"/modisco/\" + pat + \"/seqlets_\" + pat + \".tsv\"\n",
    "    seqletTmpTsv =  WORKING_DIRECTORY + \"/modisco/\" + pat + \"/seqlets_\" + pat + \".tsv\"\n",
    "    \n",
    "    seqletBed = WORKING_DIRECTORY + \"/modisco/\" + pat + \"/seqlets_\" + pat + \".bed\"\n",
    "    hitsTsv = WORKING_DIRECTORY + \"/scan/\" + pat + \".tsv\"\n",
    "    hitsTmpTsv = WORKING_DIRECTORY + \"/scan/\" + pat + \".tsv\"\n",
    "    hitsBed = WORKING_DIRECTORY + \"/scan/\" + pat + \".bed\"\n",
    "    hitsBedFilt = WORKING_DIRECTORY + \"/scan/\" + pat + \"_filt.bed\"\n",
    "    cutoffConfigDict = {\n",
    "            \"seqlets-tsv\" : seqletTmpTsv,\n",
    "            \"modisco-h5\" : WORKING_DIRECTORY + \"/modisco/\" + pat + \"/modisco.h5\",\n",
    "            \"modisco-contrib-h5\" : WORKING_DIRECTORY + \"/shap/\" + pat + \".h5\",\n",
    "            \"patterns\" : patternSpec, \n",
    "            \"seq-match-quantile\" : 0.2,\n",
    "            \"contrib-match-quantile\" : 0.2,\n",
    "            \"contrib-magnitude-quantile\" : 0.2,\n",
    "            \"trim-threshold\" : 0.3,\n",
    "            \"trim-padding\" : 1,\n",
    "            \"background-probs\" : bgProbs,\n",
    "            \"modisco-window\": 1000,\n",
    "            \"quantile-json\" : WORKING_DIRECTORY + \"/scan/\" + pat + \"_motifs.json\",\n",
    "            \"verbosity\" : LOG_LEVEL}\n",
    "    if not doneCombined:\n",
    "        # We want to run one scan with the integrated cutoffs script.\n",
    "        # (Note that still runs the cutoffs script, it just re-does it during scanning.\n",
    "        scanConfigDict = {\n",
    "            \"scan-settings\" : {\n",
    "                \"scan-contrib-h5\" : WORKING_DIRECTORY + \"/shap/\" + pat + \".h5\",\n",
    "                \"hits-tsv\" : hitsTmpTsv,\n",
    "                \"num-threads\" : NUM_THREADS_MAJOR},\n",
    "            \"seqlet-cutoff-settings\" : cutoffConfigDict,\n",
    "            \"verbosity\" : LOG_LEVEL}\n",
    "        doneCombined = True\n",
    "    else:\n",
    "        scanConfigDict = {\n",
    "            \"scan-settings\" : {\n",
    "                \"scan-contrib-h5\" : WORKING_DIRECTORY + \"/shap/\" + pat + \".h5\",\n",
    "                \"hits-tsv\" : hitsTmpTsv,\n",
    "                \"num-threads\" : NUM_THREADS_MAJOR},\n",
    "            \"seqlet-cutoff-json\" : WORKING_DIRECTORY + \"/scan/\" + pat + \"_motifs.json\",\n",
    "            \"verbosity\" : LOG_LEVEL}\n",
    "    scanFname = WORKING_DIRECTORY + \"/json/scan_\" + pat + \".json\"\n",
    "    cutoffFname = WORKING_DIRECTORY + \"/json/cutoffs_\" + pat + \".json\"\n",
    "    cmdStrScan = SCAN_BASE.format(scanFname = scanFname, cutoffFname = cutoffFname)\n",
    "    cmdStrPostproc = POSTPROC_BASE.format(seqletTmpTsv=seqletTmpTsv, scanTmpTsv = hitsTmpTsv,\n",
    "                                          seqletTsv = seqletTsv,\n",
    "                                          scanTsv = hitsTsv, scanBed = hitsBed, scanBedFilt=hitsBedFilt)\n",
    "    cmdsScan.append(cmdStrScan)\n",
    "    cmdsPostproc.append(cmdStrPostproc)\n",
    "    with open(scanFname, \"w\") as fp:\n",
    "        json.dump(scanConfigDict, fp, indent=4)\n",
    "    with open(cutoffFname, \"w\") as fp:\n",
    "        json.dump(cutoffConfigDict, fp, indent=4)\n",
    "slurmNameScan = jobsNonGpu(SLURM_CONFIG, cmdsScan, \"motifScan\", NUM_THREADS_MAJOR, 10, \"10:00:00\")\n",
    "slurmNameScanPostproc = jobsNonGpu(SLURM_CONFIG, cmdsPostproc, \"motifScanPostproc\", 3, 50, \"1:00:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b279195-5256-4b70-b45f-c5cced95b454",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobSpecs.append([slurmNameScan, [slurmNameModisco]])\n",
    "jobSpecs.append([slurmNameScanPostproc, [slurmNameScan]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71e10ea-5404-4fd5-823a-56198dc88038",
   "metadata": {},
   "source": [
    "# Generating figures with PISA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a20317-f2be-49a0-bb9b-537f72227846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an interactive test json.\n",
    "interactiveConfig = {\n",
    "    \"graph-configs\": [],\n",
    "    \"plot-configs\": [\n",
    "        {\n",
    "            \"pisa\": {\"h5-name\": WORKING_DIRECTORY + \"/shap/pisa_residual_nanog_negative.h5\"},\n",
    "             \"coordinates\": {\n",
    "                \"genome-fasta\": \"/n/data1/genomes/indexes/mm10/mm10.fa\",\n",
    "                \"midpoint-offset\": 1110,\n",
    "                \"input-slice-width\": 1000,\n",
    "                \"output-slice-width\": 1000,\n",
    "                \"genome-window-start\": 180923752,\n",
    "                \"genome-window-chrom\": \"chr1\"\n",
    "            },\n",
    "            \"importance\": {\n",
    "                \"bigwig-name\": WORKING_DIRECTORY + \"/shap/nanog_residual_counts.bw\",\n",
    "                \"show-sequence\": True\n",
    "            },\n",
    "            \"predictions\": {\n",
    "                \"bigwig-name\": WORKING_DIRECTORY + \"/pred/nanog_residual_negative.bw\"\n",
    "            },\n",
    "            \"annotations\": {\n",
    "                \"bed-name\": WORKING_DIRECTORY + \"/scan/nanog_residual_counts.bed\"\n",
    "            },\n",
    "            \"figure\": {\n",
    "                \"left\": 0.1,\n",
    "                \"bottom\": 0.1,\n",
    "                \"width\": 0.85,\n",
    "                \"height\": 0.85,\n",
    "                \"color-span\": 0.4,\n",
    "                \"diagonal-mode\": \"on\",\n",
    "                \"miniature\": False\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"width\": 7,\n",
    "    \"height\": 6,\n",
    "    \"output-gui\": True\n",
    "}\n",
    "jsonInteractivePlot = f\"{WORKING_DIRECTORY}/json/pisaInteractive.json\"\n",
    "with open(jsonInteractivePlot, \"w\") as fp:\n",
    "    json.dump(interactiveConfig, fp)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32056124-3903-44cd-82c7-97cdf993a4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I'll make plots but using the interpreter features. \n",
    "baseConfig = \"\"\"\n",
    "(lambda workdir=\"{wd:s}\", \n",
    "        tf=\"{tf:s}\",\n",
    "        strand=\"{strand:s}\",\n",
    "        mode=\"{mode:s}\":\"\"\"\n",
    "restConfig = \"\"\"\n",
    "    (lambda pisaConfig = lambda model: {\"h5-name\": workdir + \"/shap/pisa_\" + model + \"_\" + tf + \"_\" + strand + \".h5\"},\n",
    "            coordsConfig = lambda model: {\n",
    "                \"genome-fasta\": \"/n/data1/genomes/indexes/mm10/mm10.fa\",\n",
    "                \"midpoint-offset\": 1150,\n",
    "                \"input-slice-width\": 300,\n",
    "                \"output-slice-width\": 500,\n",
    "                \"genome-window-start\": 180923752,\n",
    "                \"genome-window-chrom\": \"chr1\"},\n",
    "            importanceConfig= lambda model: {\n",
    "                \"bigwig-name\": workdir + \"/shap/\" + tf + \"_\" + model + \"_profile.bw\",\n",
    "                \"show-sequence\": True},\n",
    "            predictionsConfig=lambda model: {\n",
    "                \"bigwig-name\": workdir + \"/pred/\" + tf + \"_\" + model + \"_\" + strand + \".bw\"},\n",
    "            annotationsConfig=lambda model: {\n",
    "                \"bed-name\": workdir + \"/scan/\" + tf + \"_\" + model + \"_profile_filt.bed\"},\n",
    "            figureConfig=lambda model:{\n",
    "                \"left\": {\"combined\": 0.1, \"residual\": 0.6, \"solo\": 0.1, \"transformation\": 0.6}[model],\n",
    "                \"bottom\": {\"combined\": 0.1, \"residual\": 0.1, \"solo\": 0.6, \"transformation\": 0.6}[model],\n",
    "                \"width\": 0.35,\n",
    "                \"height\": 0.35,\n",
    "                \"color-span\": 0.5,\n",
    "                \"miniature\": True}:\n",
    "        {\n",
    "            \"graph-configs\": [] if mode == \"plot\" else [{\n",
    "                    \"pisa\": pisaConfig(model),\n",
    "                    \"coordinates\":  coordsConfig(model),\n",
    "                    \"importance\":  importanceConfig(model),\n",
    "                    \"predictions\": predictionsConfig(model),\n",
    "                    \"annotations\": annotationsConfig(model),\n",
    "                    \"figure\": figureConfig(model),\n",
    "                    \"min-value\": 0.1\n",
    "                }\n",
    "                for model in [\"solo\", \"transformation\", \"combined\", \"residual\"]\n",
    "                ],\n",
    "            \"plot-configs\": [] if mode == \"graph\" else [{\n",
    "                    \"pisa\": pisaConfig(model),\n",
    "                    \"coordinates\":  coordsConfig(model),\n",
    "                    \"importance\":  importanceConfig(model),\n",
    "                    \"predictions\": predictionsConfig(model),\n",
    "                    \"annotations\": annotationsConfig(model),\n",
    "                    \"figure\": figureConfig(model)\n",
    "                }\n",
    "                for model in [\"solo\", \"transformation\", \"combined\", \"residual\"]\n",
    "                ],\n",
    "            \"width\": 7,\n",
    "            \"height\": 6,\n",
    "            \"output-png\": workdir + \"/shap/pisa_\" + tf + \"_\" + strand + \"_\" + mode + \".png\"})\n",
    "    ())()\n",
    "\"\"\"\n",
    "\n",
    "def getInterpConfig(tf, strand, mode):\n",
    "    header = baseConfig.format(wd=WORKING_DIRECTORY, tf=tf, strand=strand, mode=mode)\n",
    "    cmd = header + restConfig\n",
    "    jsonPlotFname = f\"{WORKING_DIRECTORY}/json/makeFigure_{tf}_{strand}_{mode}.json\"\n",
    "    with open(jsonPlotFname, \"w\") as fp:\n",
    "        fp.write(cmd)\n",
    "    cmds = []\n",
    "    cmds.append(constructCommand(\"makePisaFigure\") + \" {0:s}\".format(jsonPlotFname))\n",
    "    return cmds\n",
    "plotCommands = []\n",
    "for tf in TF_NAMES:\n",
    "    for strand in [\"positive\", \"negative\"]:\n",
    "        for mode in [\"plot\", \"graph\"]:\n",
    "            plotCommands.extend(getInterpConfig(tf, strand, mode))\n",
    "\n",
    "     \n",
    "slurmNameMakeInterpPlot = jobsNonGpu(SLURM_CONFIG, plotCommands, \"pisaInterpPlots\", 1, 20, \"10:00\")\n",
    "jobSpecs.append([slurmNameMakeInterpPlot, [slurmNameInterpretPisa, slurmNameInterpretFlat, slurmNamePredToBigwigCombined, slurmNamePredToBigwigSolo, slurmNamePredToBigwigTransformation, slurmNameScanPostproc]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cf4c00-89f8-4279-afaf-8823f5af9a3e",
   "metadata": {},
   "source": [
    "# Interpret from fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6bc202-8be6-4b96-8b8b-2cc8701bc5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeRegion(genome, outFp, regionStart):\n",
    "    genomeStart = regionStart - 1046\n",
    "    genomeEnd = genomeStart + INPUT_LENGTH\n",
    "    seq = genome.fetch(windowChrom, genomeStart, genomeEnd)\n",
    "    outFp.write(\">{0:d}\\n\".format(regionStart))\n",
    "    outFp.write(seq.upper())\n",
    "    outFp.write(\"\\n\")\n",
    "\n",
    "with open(WORKING_DIRECTORY + \"/shap/interp_regions.fa\", \"w\") as fafp, \\\n",
    "     open(WORKING_DIRECTORY + \"/bed/interp.bed\", \"w\") as bedfp:\n",
    "    with pysam.FastaFile(GENOME_FASTA) as genome:\n",
    "        for regionStart in range(windowStart, windowEnd + 1000, 1000):\n",
    "            writeRegion(genome, fafp, regionStart)\n",
    "            bedfp.write(\"chr1\\t{0:d}\\t{1:d}\\n\".format(regionStart, regionStart + 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3c5d1a-a472-415b-9f4e-898068992e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeInterpretFastaJson(tfNum, model):\n",
    "    return {\n",
    "        \"fasta-file\" : WORKING_DIRECTORY + \"/shap/interp_regions.fa\",\n",
    "        \"coordinates\": {\n",
    "            \"bed-file\" : WORKING_DIRECTORY + \"/bed/interp.bed\",\n",
    "            \"genome\" : GENOME_FASTA},\n",
    "        \"model-file\" : f\"{WORKING_DIRECTORY}/models/{model}.keras\",\n",
    "        \"input-length\" : INPUT_LENGTH,\n",
    "        \"output-length\" : OUTPUT_LENGTH,\n",
    "        \"heads\" : len(TF_NAMES),\n",
    "        \"head-id\": tfNum,\n",
    "        \"profile-task-ids\" : [0,1],\n",
    "        \"profile-h5\" : f\"{WORKING_DIRECTORY}/shap/{model}_{TF_NAMES[tfNum]}_fasta_profile.h5\",\n",
    "        \"counts-h5\" : f\"{WORKING_DIRECTORY}/shap/{model}_{TF_NAMES[tfNum]}_fasta_counts.h5\",\n",
    "        \"num-shuffles\" : 20,\n",
    "        \"verbosity\" : LOG_LEVEL}\n",
    "\n",
    "cmds = []\n",
    "for model in [\"joint_residual\", \"joint_combined\", \"transformation\", \"solo\"]:\n",
    "    fname = f\"{WORKING_DIRECTORY}/json/shap_fasta_{model}_{TF_NAMES[0]}.json\"\n",
    "    cmds.append(constructCommand(\"interpretFlat\") + \" {0:s}\".format(fname))\n",
    "    with open(fname, \"w\") as fp:\n",
    "        json.dump(makeInterpretFastaJson(0, model), fp)\n",
    "\n",
    "slurmNameInterpretFastaFlat = jobsGpu(SLURM_CONFIG, cmds,\n",
    "        \"interpretFastaFlat\", 5, 50, \"1:00:00\")\n",
    "jobSpecs.append([slurmNameInterpretFastaFlat, [slurmNameTrainCombined]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dad7627-7251-490f-b4ed-789476261006",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shapBwCmdBase = constructCommand(\"shapToBigwig\", doubleEscape=True) +\\\n",
    "          \"--h5 {wd:s}/shap/{model:s}_oct4_fasta_profile.h5 \" +\\\n",
    "          \"--bw {wd:s}/shap/{model:s}_oct4_fasta_profile.bw \"\n",
    "shapBwCmds = []\n",
    "for model in [\"joint_residual\", \"solo\"]:\n",
    "    cmd = shapBwCmdBase.format(wd=WORKING_DIRECTORY, model=model)\n",
    "    shapBwCmds.append(cmd)\n",
    "\n",
    "slurmNameShapFastaToBigwig = jobsNonGpu(SLURM_CONFIG, shapBwCmds, \n",
    "           \"shapFastaToBigwig\", 2, 20, \"1:00:00\")\n",
    "jobSpecs.append([slurmNameShapFastaToBigwig, [slurmNameInterpretFastaFlat]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cfd3f8-c043-46ae-9dde-021521d1a7ba",
   "metadata": {},
   "source": [
    "## Predict from fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4823dd5c-5d10-4c78-be03-330ce930282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makePredictFastaJson(tfNum):\n",
    "    return {\n",
    "        \"settings\" : {\n",
    "            \"output-h5\": WORKING_DIRECTORY + \"/pred/from_fasta.h5\",\n",
    "            \"batch-size\" : 8,\n",
    "            \"heads\" : len(TF_NAMES),\n",
    "            \"architecture\": {\n",
    "                \"model-file\" : WORKING_DIRECTORY + \"/models/joint_combined.keras\",\n",
    "                \"input-length\" : INPUT_LENGTH,\n",
    "                \"output-length\" : OUTPUT_LENGTH\n",
    "            },\n",
    "        },      \n",
    "        \"fasta-file\" : WORKING_DIRECTORY + \"/shap/interp_regions.fa\",\n",
    "        \"coordinates\": {\n",
    "            \"bed-file\" : WORKING_DIRECTORY + \"/bed/interp.bed\",\n",
    "            \"genome\" : GENOME_FASTA},\n",
    "        \"num-threads\": 2,\n",
    "        \"verbosity\" : LOG_LEVEL}\n",
    "\n",
    "cmds = []\n",
    "fname = WORKING_DIRECTORY + \"/json/predict_fasta_\" + TF_NAMES[0] + \".json\"\n",
    "cmds.append(constructCommand(\"makePredictions\") + \" {0:s}\".format(fname))\n",
    "with open(fname, \"w\") as fp:\n",
    "    json.dump(makePredictFastaJson(0), fp)\n",
    "\n",
    "slurmNamePredictFasta = jobsGpu(SLURM_CONFIG, cmds,\n",
    "        \"predictFasta\", 5, 50, \"1:00:00\")\n",
    "jobSpecs.append([slurmNamePredictFasta, [slurmNameTrainCombined]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeb1951-50b5-4151-9b75-cef0fea1b8c1",
   "metadata": {},
   "source": [
    "## Run the GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a70102-c769-4baf-9d52-09a0907d6b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmdsRunGa = []\n",
    "cmdsRunGa.append(f\"coverage run {BASE_DIRECTORY}/doc/demos/runGa.py \" +\\\n",
    "                 f\"--start 34066036 --input-len {INPUT_LENGTH} \\\n",
    "                   --chrom chr1 --model {WORKING_DIRECTORY}/models/joint_residual.keras --genome {GENOME_FASTA} \\\n",
    "                   --output {WORKING_DIRECTORY}/logs/gaOutput.json\")\n",
    "slurmNameRunGa = jobsGpu(SLURM_CONFIG, cmdsRunGa, \"runGa\", 5, 50, \"0:10:00\")\n",
    "jobSpecs.append([slurmNameRunGa, [slurmNameTrainCombined]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f9077b-e882-4f59-b5b9-6a1b7945e307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7bd150c-b22a-460e-8714-41ce393dfc62",
   "metadata": {},
   "source": [
    "# Test the ISM mode for the interpretation tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c6e9bf-ffb2-486c-9efc-ab299e200b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ismScriptExe = f\"{BASE_DIRECTORY}/doc/demos/testIsm.py\"\n",
    "def makeInterpretIsmJson(model, modelName):\n",
    "    return {\n",
    "        \"genome\" : GENOME_FASTA,\n",
    "        \"bed-file\" : WORKING_DIRECTORY + \"/bed/interp.bed\",\n",
    "        \"model-file\" : f\"{WORKING_DIRECTORY}/models/{model}.keras\", \n",
    "        \"input-length\" : INPUT_LENGTH,\n",
    "        \"output-length\" : OUTPUT_LENGTH,\n",
    "        \"heads\" : len(TF_NAMES),\n",
    "        \"head-id\": tfNum,\n",
    "        \"profile-task-ids\" : [0,1],\n",
    "        \"profile-h5\" : f\"{WORKING_DIRECTORY}/shap/ism_{TF_NAMES[tfNum]}_{modelName}_profile.h5\",\n",
    "        \"counts-h5\" : f\"{WORKING_DIRECTORY}/shap/ism_{TF_NAMES[tfNum]}_{modelName}_counts.h5\",\n",
    "        \"kmer-size\" : 11,\n",
    "        \"verbosity\" : LOG_LEVEL}\n",
    "cmds = []\n",
    "fname = f\"{WORKING_DIRECTORY}/json/ism_{TF_NAMES[0]}_residual.json\"\n",
    "cmds.append(constructCommand(ismScriptExe, shortProgName=\"interpretISM\") + \"{0:s}\".format(fname))\n",
    "with open(fname, \"w\") as fp:\n",
    "    json.dump(makeInterpretIsmJson(\"joint_residual\", \"residual\"), fp)\n",
    "slurmNameInterpretIsm = jobsGpu(SLURM_CONFIG, cmds,\n",
    "        \"interpretIsm\", 5, 50, \"10:00:00\")\n",
    "jobSpecs.append([slurmNameInterpretIsm, [slurmNameTrainCombined]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131df5e6-78f7-4cfb-a308-1fde8aeb8f2f",
   "metadata": {},
   "source": [
    "# Write entire script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06a70f5-0efd-4693-96b9-8267190a4c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScriptName(longName):\n",
    "    return longName.split('/')[-1][:-6]\n",
    "lastChild = \"\"\n",
    "for e in jobSpecs:\n",
    "    parents = [getScriptName(x) for x in e[1]]\n",
    "    child = getScriptName(e[0])\n",
    "    if len(parents) == 1 and parents[0] == lastChild:\n",
    "        parents = '\"\"'\n",
    "    print(\"{0:25s}    {1:20s}\".format(str(parents), child))\n",
    "    lastChild = child\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6aac6d-ed0c-4c23-ac6e-dcf10bd2fbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "writeDependencyScript(SLURM_CONFIG, jobSpecs, \"acceptance\", cancelScript = WORKING_DIRECTORY + \"/slurm/cancel.zsh\")\n",
    "finalScript=f\"\"\"#!/usr/bin/env zsh\n",
    "source /home/cm2363/.zshrc\n",
    "{SLURM_CONFIG[\"condaString\"]}\n",
    "cat {WORKING_DIRECTORY}/logs/trainCombined* | coverage run $(which showTrainingProgress) --exit-delay 0;\n",
    "head -n 200 {WORKING_DIRECTORY}/logs/trainCombined* | coverage run $(which showTrainingProgress) --exit-delay 1;\n",
    "coverage combine --append --keep\n",
    "coverage html\n",
    "\"\"\"\n",
    "with open(f\"{WORKING_DIRECTORY}/slurm/atFinish.zsh\", \"w\") as fp:\n",
    "    fp.write(finalScript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebb3bb2-ba9a-499f-b063-c8c2cdbf7b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "1/0 # STOP HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a292886f-190a-4024-8ede-286fb9f2a08b",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a0aba3-efb8-457a-9dcc-39c51a2bb03f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceaeaab-f679-45f0-a0b0-d91ae384c513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c0974e-039b-413b-bd6a-49cf6dd3e4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's also take a quick look at the generated bigwigs. \n",
    "\n",
    "def plotBws(bwNames, titles, chrom, start, stop):\n",
    "    \n",
    "    for i, bwName in enumerate(bwNames):\n",
    "        plt.subplot(100*len(bwNames)+10+(i+1))\n",
    "        bw = pyBigWig.open(bwName)\n",
    "        bwVals = np.nan_to_num(bw.values(chrom, start, stop))\n",
    "        #plt.xlim(0,stop-start)\n",
    "        plt.bar(range(start, stop), bwVals, width=1)\n",
    "        plt.ylabel(titles[i])\n",
    "        if(i < len(bwNames)-1):\n",
    "            plt.xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e726e521-11c4-4509-a2f2-3f7bd69cac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotBws([DATA_DIRECTORY + \"/patchcap/counts.pos.bw\",\n",
    "#          WORKING_DIRECTORY + \"/pred/patchcap_positive.bw\",\n",
    "#          DATA_DIRECTORY + \"/patchcap/counts.neg.bw\", \n",
    "#          WORKING_DIRECTORY + \"/pred/patchcap_negative.bw\"],\n",
    "#         [\"exptl_pos\", \"pred_pos\", \"exptl_neg\", \"pred_neg\"], \"chr1\", 34076750, 34077750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8f7f20-5a15-4e99-bcfd-6bb303749dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotBws([DATA_DIRECTORY + \"/patchcap/counts.pos.bw\",\n",
    "#          WORKING_DIRECTORY + \"/pred/transform_positive.bw\",\n",
    "#          DATA_DIRECTORY + \"/nanog/counts.pos.bw\"],\n",
    "#         [\"pc_pos\", \"transform_pos\", \"exptl_pos\"], \"chr1\", 34076750, 34077750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40efd93-e50f-4afe-920c-4f7c80b085f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d3e005-62ed-45b5-821b-843af1d97485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTfBigwigs(tfName, exptName, startPos = 34066036, span=1000, chrom=\"chr1\"):\n",
    "    plotBws([DATA_DIRECTORY + \"/\" + tfName + \"/counts.pos.bw\",\n",
    "             WORKING_DIRECTORY + \"/pred/\" + tfName + \"_\" + exptName + \"_positive.bw\",\n",
    "             DATA_DIRECTORY + \"/\" + tfName + \"/counts.neg.bw\", \n",
    "             WORKING_DIRECTORY + \"/pred/\" + tfName + \"_\" + exptName + \"_negative.bw\"],\n",
    "            [\"exptl_pos\", \"pred_pos\", \"exptl_neg\", \"pred_neg\"], chrom, startPos, startPos+span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36270caa-f839-4b12-b3e4-c7799ff78aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTfBigwigs('oct4', 'combined', startPos = 180924752, span=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e88cfe-e5b1-4e96-8a70-3b281662a9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTfBigwigs('nanog', 'combined', startPos = 180924752, span=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c325738c-4a39-45e5-a1dc-8ebb1fef843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTfBigwigs('oct4', 'residual', startPos = 180924752, span=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f6c80b-7611-4b7c-b6f2-4aeea1409f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotShapBigwigs(tfName, exptName, startPos = 34066036, span=1000, chrom=\"chr1\"):\n",
    "    plotBws([WORKING_DIRECTORY + \"/pred/\" + tfName + \"_\" + exptName + \"_positive.bw\",\n",
    "             WORKING_DIRECTORY + \"/pred/\" + tfName + \"_\" + exptName + \"_negative.bw\",\n",
    "             WORKING_DIRECTORY + \"/shap/\" + tfName + \"_residual_profile.bw\", \n",
    "             WORKING_DIRECTORY + \"/shap/\" + tfName + \"_residual_counts.bw\"],\n",
    "            [\"pred_pos\", \"pred_neg\", \"profile\", \"counts\"], chrom, startPos, startPos+span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4175441d-34f2-4c85-bc26-d46015f25f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotShapBigwigs('nanog', 'residual', startPos = 180924752, span=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49bc6a5-c23e-4647-a72d-423622350791",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotShapBigwigs('oct4', 'residual', startPos = 180924752, span=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987dc0af-ce1f-4666-af6e-0a9da902c624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccc4020-fd82-48f9-b712-82b42365cb30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b606f17-18fe-4c2e-afe3-3b3610a5ec68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012678b2-da2e-4b0d-99e4-7377672b5e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'll generate all of those figures and save them.\n",
    "runName, run = list(patternsToScan.items())[2]\n",
    "clusterName, cluster = list(run.items())[0]\n",
    "motif = cluster[0]\n",
    "pat = motifUtils.Pattern(clusterName + \"_patterns\", \"pattern_{0:d}\".format(motif[0]), motif[1])\n",
    "with h5py.File(WORKING_DIRECTORY + \"/modisco/\" + runName + \"/modisco.h5\", \"r\") as fp:\n",
    "    pat.loadCwm(fp, 0.3, 3, bgProbs)\n",
    "    pat.loadSeqlets(fp)\n",
    "fig = plt.figure()\n",
    "bprplots.plotModiscoPattern(pat, fig, sortKey = [x.contribMatch for x in pat.seqlets])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe75fbe-b2a4-4318-b0b3-8647b98a4177",
   "metadata": {},
   "source": [
    "## PISA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1e93c7-17b5-4d5d-b5c9-2e886708b894",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "pisaSection = {\n",
    "    \"h5-name\": WORKING_DIRECTORY + \"/shap/pisa_residual_nanog_positive.h5\"\n",
    "}\n",
    "\n",
    "coordinatesSection = {\n",
    "    \"genome-fasta\": GENOME_FASTA,\n",
    "    \"midpoint-offset\": 1150,\n",
    "    \"input-slice-width\": 200,\n",
    "    \"output-slice-width\": 300,\n",
    "    \"genome-window-start\": windowStart,\n",
    "    \"genome-window-chrom\": windowChrom\n",
    "}\n",
    "\n",
    "predictionSection = {\n",
    "    \"bigwig-name\": WORKING_DIRECTORY + \"/pred/nanog_residual_positive.bw\",\n",
    "    \"show-sequence\": False,\n",
    "    \"color\": {\"tol\": 0}\n",
    "}\n",
    "\n",
    "importanceSection = {\n",
    "    \"bigwig-name\": WORKING_DIRECTORY + \"/shap/nanog_residual_profile.bw\",\n",
    "    \"show-sequence\": True,\n",
    "    \"color\": bprcolors.dnaWong\n",
    "}\n",
    "\n",
    "annotationSection = {\n",
    "    \"bed-name\": WORKING_DIRECTORY + \"/scan/nanog_residual_profile.bed\",\n",
    "    \"custom\": []\n",
    "}\n",
    "\n",
    "figureSectionPlot = {\n",
    "    \"left\": 0.1,\n",
    "    \"bottom\": 0.55,\n",
    "    \"width\": 0.9,\n",
    "    \"height\": 0.4,\n",
    "    \"annotation-height\": 0.15,\n",
    "    \"tick-font-size\" : 6,\n",
    "    \"label-font-size\" : 8,\n",
    "    \"color-span\": 0.5,\n",
    "    \"grid-mode\": \"on\",\n",
    "    \"diagonal-mode\": \"on\",\n",
    "    \"miniature\": False\n",
    "}\n",
    "\n",
    "plotConfig = {\n",
    "    \"pisa\": pisaSection,\n",
    "    \"coordinates\": coordinatesSection,\n",
    "    \"importance\": importanceSection,\n",
    "    \"predictions\": predictionSection,\n",
    "    \"annotations\": annotationSection,\n",
    "    \"figure\": figureSectionPlot\n",
    "}\n",
    "\n",
    "figureSectionGraph = {\n",
    "    \"left\": 0.1,\n",
    "    \"bottom\": 0.05,\n",
    "    \"width\": 0.9,\n",
    "    \"height\": 0.4,\n",
    "    \"annotation-height\": 0.15,\n",
    "    \"tick-font-size\" : 6,\n",
    "    \"label-font-size\" : 8,\n",
    "    \"color-span\": 0.5\n",
    "}\n",
    "\n",
    "graphConfig = {\n",
    "    \"pisa\": pisaSection,\n",
    "    \"coordinates\": coordinatesSection,\n",
    "    \"importance\": importanceSection,\n",
    "    \"predictions\": predictionSection,\n",
    "    \"annotations\": annotationSection,\n",
    "    \"figure\": figureSectionGraph,\n",
    "    \"min-value\": 0.1,\n",
    "    \"use-annotation-colors\": True\n",
    "}\n",
    "rPlot = bprplots.plotPisa(plotConfig, fig)\n",
    "rGraph = bprplots.plotPisaGraph(graphConfig, fig);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea46fa55-06a8-489f-a0a8-469b7a97911a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "rGraph[\"config\"][\"figure\"][\"line-width\"] = 2\n",
    "rPlot2 = bprplots.plotPisa(rPlot[\"config\"], fig)\n",
    "rGraph2 = bprplots.plotPisaGraph(rGraph[\"config\"], fig);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5df1616-a3a8-4570-b18c-3af2e7dd9447",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "bprplots.plotPisa(rPlot2[\"config\"], fig)\n",
    "bprplots.plotPisaGraph(rGraph2[\"config\"], fig);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d3a1cb-336e-4b21-a568-7959c1d1dcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "fig.add_axes([0,0,1,1])\n",
    "pisaSectionCombined = {\n",
    "    \"h5-name\": WORKING_DIRECTORY + \"/shap/pisa_combined_nanog_positive.h5\"\n",
    "}\n",
    "\n",
    "pisaSectionResidual = {\n",
    "    \"h5-name\": WORKING_DIRECTORY + \"/shap/pisa_residual_nanog_positive.h5\"\n",
    "}\n",
    "\n",
    "pisaSectionTransformation = {\n",
    "    \"h5-name\": WORKING_DIRECTORY + \"/shap/pisa_transformation_nanog_positive.h5\"\n",
    "}\n",
    "\n",
    "pisaSectionSolo = {\n",
    "    \"h5-name\": WORKING_DIRECTORY + \"/shap/pisa_solo_nanog_positive.h5\"\n",
    "}\n",
    "\n",
    "\n",
    "coordinatesSection = {\n",
    "    \"genome-fasta\": GENOME_FASTA,\n",
    "    \"midpoint-offset\": 1150,\n",
    "    \"input-slice-width\": 300,\n",
    "    \"output-slice-width\": 500,\n",
    "    \"genome-window-start\": windowStart,\n",
    "    \"genome-window-chrom\": windowChrom\n",
    "}\n",
    "\n",
    "predictionSectionCombined = {\n",
    "    \"bigwig-name\": WORKING_DIRECTORY + \"/pred/nanog_combined_positive.bw\"\n",
    "}\n",
    "\n",
    "predictionSectionResidual = {\n",
    "    \"bigwig-name\": WORKING_DIRECTORY + \"/pred/nanog_residual_positive.bw\"\n",
    "}\n",
    "\n",
    "predictionSectionTransformation = {\n",
    "    \"bigwig-name\": WORKING_DIRECTORY + \"/pred/nanog_transformation_positive.bw\"\n",
    "}\n",
    "\n",
    "predictionSectionSolo = {\n",
    "    \"bigwig-name\": WORKING_DIRECTORY + \"/pred/nanog_solo_positive.bw\"\n",
    "}\n",
    "\n",
    "importanceSectionSolo = {\n",
    "    \"bigwig-name\": WORKING_DIRECTORY + \"/shap/nanog_solo_profile.bw\",\n",
    "    \"show-sequence\": True\n",
    "}\n",
    "\n",
    "importanceSectionTransformation = {\n",
    "    \"bigwig-name\": WORKING_DIRECTORY + \"/shap/nanog_transformation_profile.bw\",\n",
    "    \"show-sequence\": True\n",
    "}\n",
    "\n",
    "importanceSectionCombined = {\n",
    "    \"bigwig-name\": WORKING_DIRECTORY + \"/shap/nanog_combined_profile.bw\",\n",
    "    \"show-sequence\": True\n",
    "}\n",
    "\n",
    "importanceSectionResidual = {\n",
    "    \"bigwig-name\": WORKING_DIRECTORY + \"/shap/nanog_residual_profile.bw\",\n",
    "    \"show-sequence\": True\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "annotationSection = {\n",
    "    \"bed-name\": WORKING_DIRECTORY + \"/scan/nanog_residual_profile.bed\"\n",
    "}\n",
    "def getFig(offX, offY):\n",
    "    figureSectionPlot = {\n",
    "        \"left\": 0.1 + offX,\n",
    "        \"bottom\": 0.1 + offY,\n",
    "        \"width\": 0.35,\n",
    "        \"height\": 0.35,\n",
    "        \"color-span\": 0.5,\n",
    "        \"miniature\": True\n",
    "    }\n",
    "    return figureSectionPlot\n",
    "\n",
    "plotConfigCombined = {\n",
    "    \"pisa\": pisaSectionCombined,\n",
    "    \"coordinates\": coordinatesSection,\n",
    "    \"importance\": importanceSectionCombined,\n",
    "    \"predictions\": predictionSectionCombined,\n",
    "    \"annotations\": annotationSection,\n",
    "    \"figure\": getFig(0, 0)\n",
    "}\n",
    "\n",
    "bprplots.plotPisa(plotConfigCombined, fig);\n",
    "\n",
    "plotConfigResidual = {\n",
    "    \"pisa\": pisaSectionResidual,\n",
    "    \"coordinates\": coordinatesSection,\n",
    "    \"importance\": importanceSectionResidual,\n",
    "    \"predictions\": predictionSectionResidual,\n",
    "    \"annotations\": annotationSection,\n",
    "    \"figure\": getFig(0.5, 0)\n",
    "}\n",
    "\n",
    "bprplots.plotPisa(plotConfigResidual, fig);\n",
    "\n",
    "\n",
    "plotConfigTransformation = {\n",
    "    \"pisa\": pisaSectionTransformation,\n",
    "    \"coordinates\": coordinatesSection,\n",
    "    \"importance\": importanceSectionTransformation,\n",
    "    \"predictions\": predictionSectionTransformation,\n",
    "    \"annotations\": annotationSection,\n",
    "    \"figure\": getFig(0.5, 0.5)\n",
    "}\n",
    "\n",
    "bprplots.plotPisa(plotConfigTransformation, fig);\n",
    "\n",
    "\n",
    "\n",
    "plotConfigSolo = {\n",
    "    \"pisa\": pisaSectionSolo,\n",
    "    \"coordinates\": coordinatesSection,\n",
    "    \"importance\": importanceSectionSolo,\n",
    "    \"predictions\": predictionSectionSolo,\n",
    "    \"annotations\": annotationSection,\n",
    "    \"figure\": getFig(0, 0.5)\n",
    "}\n",
    "\n",
    "\n",
    "bprplots.plotPisa(plotConfigSolo, fig);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e31e3bd-11e2-43d0-83f1-bcf7c6a981c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from bpreveal import gaOptimize\n",
    "with open(f\"{WORKING_DIRECTORY}/logs/gaOutput.json\", \"r\") as fp:\n",
    "    j = json.load(fp)\n",
    "    origProf = np.array(j[\"origProfile\"])\n",
    "    prof = np.array(j[\"profile\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d81b9e3-f135-4d8a-b437-154e25fbbbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptr = [(prof[x,:,0], \"oskn\"[x], \"rgbk\"[x]) for x in range(4)]\n",
    "ntr = [(prof[x,:,1], \"oskn\"[x], \"rgbk\"[x]) for x in range(4)]\n",
    "ax = plt.axes()\n",
    "cors = gaOptimize.stringToCorruptorList(j[\"corruptors\"])\n",
    "print(cors)\n",
    "cors_fix = [(x[0] + 34066036 - (INPUT_LENGTH - OUTPUT_LENGTH) //2, x[1]) for x in cors]\n",
    "gaOptimize.plotTraces(ptr, ntr, range(34066036, 34067036), [], cors_fix, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9ac18b-9339-4e68-99f4-08936b3dcc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    plt.subplot(421+i*2)\n",
    "    plt.plot(origProf[i,:,0], \"g-\")\n",
    "    plt.plot(-origProf[i,:,1], \"g-\")\n",
    "    plt.subplot(422+i*2)\n",
    "    plt.plot(prof[i,:,0], \"r-\")\n",
    "    plt.plot(-prof[i,:,1], \"r-\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee532ed4-685a-4d51-a39f-9fc785486a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pisaVals = {}\n",
    "def loadVals(fname):\n",
    "    if fname in pisaVals:\n",
    "        return np.array(pisaVals[fname])\n",
    "    with h5py.File(fname, \"r\") as fp:\n",
    "        pdats = np.sum(np.abs(np.sum(fp[\"shap\"], axis=2)), axis=0)\n",
    "    pisaVals[fname] = pdats\n",
    "    return np.array(pisaVals[fname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c175f761-c15a-44d2-ad56-15cd0ab72218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9285e8e-bbb6-4088-ad7d-a3c902f92abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addPlot(model, strand, color, label):\n",
    "    \n",
    "    pdats = loadVals(f\"{WORKING_DIRECTORY}/shap/pisa_{model}_oct4_{strand}.h5\")\n",
    "    for tf in TF_NAMES:\n",
    "        if tf != \"oct4\":\n",
    "            pdats += loadVals(f\"{WORKING_DIRECTORY}/shap/pisa_{model}_{tf}_{strand}.h5\")\n",
    "    xvals = np.arange(-pdats.shape[0] // 2, pdats.shape[0] // 2)\n",
    "    plt.semilogy(xvals, pdats, color=color, label=label)\n",
    "def makeAll():\n",
    "    addPlot(\"combined\", \"positive\", \"#FF0000\", \"Combined\")\n",
    "    addPlot(\"combined\", \"negative\", \"#FF9999\", None)\n",
    "    addPlot(\"solo\", \"positive\", \"#00FF00\", \"Solo\")\n",
    "    addPlot(\"solo\", \"negative\", \"#99FF99\", None)\n",
    "    addPlot(\"residual\", \"positive\", \"#0000FF\", \"Residual\")\n",
    "    addPlot(\"residual\", \"negative\", \"#9999FF\", None)\n",
    "plt.subplot(212)\n",
    "makeAll()\n",
    "plt.legend()\n",
    "plt.xlim(-20, 20)\n",
    "plt.ylim(50, 5000)\n",
    "plt.grid()\n",
    "plt.subplot(211)\n",
    "makeAll()\n",
    "plt.legend()\n",
    "plt.xlim(-1000, 1000)\n",
    "plt.ylim(0.1, 5000)\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4da51b-5056-493a-a6c8-9d98ddd52a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf7450b-46b6-40c1-96cb-3b49d42b8fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ed5759-39aa-43e0-a214-1059493edabf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
